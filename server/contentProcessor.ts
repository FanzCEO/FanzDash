import { EventEmitter } from "events";
import { promises as fs } from "fs";
import { join, extname } from "path";
import { randomUUID } from "crypto";
import { spawn } from "child_process";
import OpenAI from "openai";

// Development-safe OpenAI initialization
const isDevMode = !process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY.includes("placeholder") || process.env.OPENAI_API_KEY.includes("development");
const openai = isDevMode ? null : new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export interface ContentItem {
  id: string;
  type: "image" | "video" | "audio" | "text" | "document";
  originalPath: string;
  processedPaths: Record<string, string>;
  metadata: ContentMetadata;
  analysis: ContentAnalysis;
  status: "pending" | "processing" | "completed" | "failed";
  uploadTime: Date;
  processTime?: Date;
  userId: string;
  tags: string[];
  categories: string[];
  nsfw: boolean;
  approved: boolean;
  moderationFlags: string[];
}

export interface ContentMetadata {
  filename: string;
  size: number;
  mimeType: string;
  duration?: number;
  dimensions?: { width: number; height: number };
  bitrate?: number;
  codec?: string;
  fps?: number;
  colorSpace?: string;
  quality?: number;
  hash: string;
}

export interface ContentAnalysis {
  aiScore: number;
  confidence: number;
  categories: Array<{ name: string; confidence: number }>;
  objects: Array<{ name: string; confidence: number; bbox?: number[] }>;
  faces: Array<{
    bbox: number[];
    age?: number;
    gender?: string;
    emotion?: string;
  }>;
  text?: string;
  language?: string;
  sentiment?: { score: number; magnitude: number };
  adult: { score: number; category: string };
  violence: { score: number; category: string };
  medical: { score: number; category: string };
  racy: { score: number; category: string };
  technical: {
    sharpness: number;
    brightness: number;
    contrast: number;
    noise: number;
  };
}

export interface ProcessingTask {
  id: string;
  contentId: string;
  type: "analyze" | "transcode" | "thumbnail" | "optimize" | "watermark";
  priority: number;
  status: "pending" | "processing" | "completed" | "failed";
  progress: number;
  startTime?: Date;
  endTime?: Date;
  error?: string;
  result?: any;
}

export class ContentProcessor extends EventEmitter {
  private content = new Map<string, ContentItem>();
  private tasks = new Map<string, ProcessingTask>();
  private processingQueue: ProcessingTask[] = [];
  private activeProcesses = 0;
  private maxConcurrentProcesses = 4;

  constructor() {
    super();
    this.setupDirectories();
    this.startProcessingLoop();
  }

  private async setupDirectories() {
    const dirs = [
      "content/original",
      "content/processed",
      "content/thumbnails",
      "content/optimized",
      "content/watermarked",
      "content/transcoded",
      "content/temp",
    ];

    for (const dir of dirs) {
      await fs.mkdir(join(process.cwd(), "media", dir), { recursive: true });
    }
  }

  async processContent(
    filePath: string,
    userId: string,
    options: {
      type?: ContentItem["type"];
      autoApprove?: boolean;
      generateThumbnails?: boolean;
      generateOptimized?: boolean;
      analyzeContent?: boolean;
      extractText?: boolean;
    } = {},
  ): Promise<string> {
    const contentId = randomUUID();
    const filename = filePath.split("/").pop() || "unknown";
    const fileStats = await fs.stat(filePath);

    // Determine content type
    const ext = extname(filename).toLowerCase();
    const type = options.type || this.detectContentType(ext);

    // Calculate file hash for deduplication
    const hash = await this.calculateFileHash(filePath);

    // Check for duplicates
    const duplicate = Array.from(this.content.values()).find(
      (item) => item.metadata.hash === hash,
    );

    if (duplicate) {
      throw new Error(`Duplicate content detected: ${duplicate.id}`);
    }

    const contentItem: ContentItem = {
      id: contentId,
      type,
      originalPath: filePath,
      processedPaths: {},
      metadata: {
        filename,
        size: fileStats.size,
        mimeType: this.getMimeType(ext),
        hash,
      },
      analysis: {
        aiScore: 0,
        confidence: 0,
        categories: [],
        objects: [],
        faces: [],
        adult: { score: 0, category: "unknown" },
        violence: { score: 0, category: "unknown" },
        medical: { score: 0, category: "unknown" },
        racy: { score: 0, category: "unknown" },
        technical: {
          sharpness: 0,
          brightness: 0,
          contrast: 0,
          noise: 0,
        },
      },
      status: "pending",
      uploadTime: new Date(),
      userId,
      tags: [],
      categories: [],
      nsfw: false,
      approved: options.autoApprove || false,
      moderationFlags: [],
    };

    this.content.set(contentId, contentItem);

    // Create processing tasks
    const tasks: Omit<ProcessingTask, "id">[] = [];

    if (options.analyzeContent !== false) {
      tasks.push({
        contentId,
        type: "analyze",
        priority: 10,
        status: "pending",
        progress: 0,
      });
    }

    if (
      options.generateThumbnails !== false &&
      ["image", "video"].includes(type)
    ) {
      tasks.push({
        contentId,
        type: "thumbnail",
        priority: 8,
        status: "pending",
        progress: 0,
      });
    }

    if (options.generateOptimized !== false) {
      tasks.push({
        contentId,
        type: "optimize",
        priority: 6,
        status: "pending",
        progress: 0,
      });
    }

    if (type === "video") {
      tasks.push({
        contentId,
        type: "transcode",
        priority: 7,
        status: "pending",
        progress: 0,
      });
    }

    // Add tasks to queue
    for (const taskData of tasks) {
      const task: ProcessingTask = {
        ...taskData,
        id: randomUUID(),
      };
      this.tasks.set(task.id, task);
      this.processingQueue.push(task);
    }

    // Sort queue by priority
    this.processingQueue.sort((a, b) => b.priority - a.priority);

    this.emit("contentAdded", contentItem);
    return contentId;
  }

  private async startProcessingLoop() {
    setInterval(() => {
      this.processNextTask();
    }, 1000);
  }

  private async processNextTask() {
    if (this.activeProcesses >= this.maxConcurrentProcesses) return;
    if (this.processingQueue.length === 0) return;

    const task = this.processingQueue.shift()!;
    this.activeProcesses++;

    task.status = "processing";
    task.startTime = new Date();
    this.emit("taskStarted", task);

    try {
      await this.executeTask(task);
      task.status = "completed";
      task.endTime = new Date();
      task.progress = 100;
      this.emit("taskCompleted", task);
    } catch (error) {
      task.status = "failed";
      task.error = error instanceof Error ? error.message : "Unknown error";
      task.endTime = new Date();
      this.emit("taskFailed", task);
    }

    this.activeProcesses--;
  }

  private async executeTask(task: ProcessingTask) {
    const content = this.content.get(task.contentId);
    if (!content) throw new Error("Content not found");

    switch (task.type) {
      case "analyze":
        await this.analyzeContent(content, task);
        break;
      case "thumbnail":
        await this.generateThumbnails(content, task);
        break;
      case "optimize":
        await this.optimizeContent(content, task);
        break;
      case "transcode":
        await this.transcodeVideo(content, task);
        break;
      case "watermark":
        await this.addWatermark(content, task);
        break;
      default:
        throw new Error(`Unknown task type: ${task.type}`);
    }
  }

  private async analyzeContent(content: ContentItem, task: ProcessingTask) {
    task.progress = 10;

    // Extract metadata first
    await this.extractMetadata(content);
    task.progress = 30;

    // AI-powered content analysis
    switch (content.type) {
      case "image":
        await this.analyzeImage(content);
        break;
      case "video":
        await this.analyzeVideo(content);
        break;
      case "audio":
        await this.analyzeAudio(content);
        break;
      case "text":
        await this.analyzeText(content);
        break;
    }

    task.progress = 80;

    // Apply moderation rules
    this.applyModerationRules(content);

    task.progress = 100;
    content.status = "completed";
    content.processTime = new Date();
  }

  private async extractMetadata(content: ContentItem) {
    if (["image", "video", "audio"].includes(content.type)) {
      return new Promise<void>((resolve, reject) => {
        const process = spawn("ffprobe", [
          "-v",
          "quiet",
          "-print_format",
          "json",
          "-show_format",
          "-show_streams",
          content.originalPath,
        ]);

        let output = "";

        process.stdout.on("data", (data) => {
          output += data.toString();
        });

        process.on("close", (code) => {
          if (code !== 0) {
            reject(new Error("Failed to extract metadata"));
            return;
          }

          try {
            const data = JSON.parse(output);
            const format = data.format;
            const videoStream = data.streams.find(
              (s: any) => s.codec_type === "video",
            );
            const audioStream = data.streams.find(
              (s: any) => s.codec_type === "audio",
            );

            content.metadata.duration =
              parseFloat(format.duration) || undefined;
            content.metadata.bitrate = parseInt(format.bit_rate) || undefined;

            if (videoStream) {
              content.metadata.dimensions = {
                width: videoStream.width,
                height: videoStream.height,
              };
              // Parse frame rate safely (format: "30/1" or "24000/1001")
              const frameRateParts = videoStream.r_frame_rate?.split('/');
              content.metadata.fps = frameRateParts?.length === 2 
                ? parseFloat(frameRateParts[0]) / parseFloat(frameRateParts[1]) 
                : undefined;
              content.metadata.codec = videoStream.codec_name;
              content.metadata.colorSpace = videoStream.color_space;
            }

            resolve();
          } catch (error) {
            reject(error);
          }
        });
      });
    }
  }

  private async analyzeImage(content: ContentItem) {
    if (isDevMode) {
      console.log("ðŸ”§ Development mode: Using mock image analysis");
      // Mock analysis response
      content.analysis = {
        aiScore: Math.random() * 30, // Low risk for dev
        confidence: 85,
        categories: [{ name: "image", confidence: 0.9 }],
        objects: [{ name: "person", confidence: 0.8 }],
        faces: [],
        adult: { score: Math.random() * 20, category: "safe" },
        violence: { score: Math.random() * 10, category: "none" },
        medical: { score: Math.random() * 15, category: "none" },
        racy: { score: Math.random() * 25, category: "none" },
        technical: { sharpness: 75, brightness: 60, contrast: 65, noise: 15 },
      };
      return;
    }

    // Read image file as base64
    const imageBuffer = await fs.readFile(content.originalPath);
    const base64Image = imageBuffer.toString("base64");

    // Analyze with OpenAI Vision
    const response = await openai!.chat.completions.create({
      model: "gpt-4o", // Vision model
      messages: [
        {
          role: "user",
          content: [
            {
              type: "text",
              text: `Analyze this image for content moderation. Provide a JSON response with:
              - categories: array of content categories with confidence scores
              - adult: {score: 0-100, category: "safe/suggestive/explicit"}
              - violence: {score: 0-100, category: "none/mild/moderate/severe"}
              - medical: {score: 0-100, category: "none/mild/moderate/severe"}  
              - racy: {score: 0-100, category: "none/mild/moderate/severe"}
              - objects: array of detected objects with confidence
              - faces: array of detected faces with demographics if visible
              - technical: {sharpness: 0-100, brightness: 0-100, contrast: 0-100, noise: 0-100}
              - overall_score: 0-100 (higher = more likely to need moderation)`,
            },
            {
              type: "image_url",
              image_url: {
                url: `data:image/jpeg;base64,${base64Image}`,
              },
            },
          ],
        },
      ],
      response_format: { type: "json_object" },
      max_tokens: 1000,
    });

    const analysis = JSON.parse(response.choices[0].message.content!);

    // Map analysis to our structure
    content.analysis = {
      aiScore: analysis.overall_score || 0,
      confidence: 85, // GPT-4o confidence
      categories: analysis.categories || [],
      objects: analysis.objects || [],
      faces: analysis.faces || [],
      adult: analysis.adult || { score: 0, category: "safe" },
      violence: analysis.violence || { score: 0, category: "none" },
      medical: analysis.medical || { score: 0, category: "none" },
      racy: analysis.racy || { score: 0, category: "none" },
      technical: analysis.technical || {
        sharpness: 50,
        brightness: 50,
        contrast: 50,
        noise: 20,
      },
    };
  }

  private async analyzeVideo(content: ContentItem) {
    // Extract keyframes for analysis
    const framesDir = join(
      process.cwd(),
      "media",
      "content",
      "temp",
      content.id,
    );
    await fs.mkdir(framesDir, { recursive: true });

    // Extract 5 frames at different intervals
    const duration = content.metadata.duration || 10;
    const intervals = [0.1, 0.3, 0.5, 0.7, 0.9].map((p) => p * duration);

    const frameAnalyses: any[] = [];

    for (let i = 0; i < intervals.length; i++) {
      const framePath = join(framesDir, `frame_${i}.jpg`);

      // Extract frame
      await new Promise<void>((resolve, reject) => {
        const process = spawn("ffmpeg", [
          "-i",
          content.originalPath,
          "-ss",
          intervals[i].toString(),
          "-vframes",
          "1",
          "-y",
          framePath,
        ]);

        process.on("close", (code) => {
          if (code === 0) resolve();
          else reject(new Error("Frame extraction failed"));
        });
      });

      // Analyze frame
      const frameBuffer = await fs.readFile(framePath);
      const base64Frame = frameBuffer.toString("base64");

      if (isDevMode) {
        console.log(`ðŸ”§ Development mode: Using mock frame analysis ${i + 1}/${intervals.length}`);
        frameAnalyses.push({
          overall_score: Math.random() * 25,
          adult_score: Math.random() * 15,
          violence_score: Math.random() * 10,
          medical_score: Math.random() * 12,
          racy_score: Math.random() * 20,
          adult_category: "safe",
          violence_category: "none",
          medical_category: "none",
          racy_category: "none",
          sharpness: 70 + Math.random() * 20,
          brightness: 50 + Math.random() * 30,
          contrast: 60 + Math.random() * 25,
          noise: 10 + Math.random() * 20
        });
      } else {
        const response = await openai!.chat.completions.create({
          model: "gpt-4o",
          messages: [
            {
              role: "user",
              content: [
                {
                  type: "text",
                  text: "Analyze this video frame for adult content, violence, and other moderation concerns. Return JSON with scores 0-100.",
                },
                {
                  type: "image_url",
                  image_url: {
                    url: `data:image/jpeg;base64,${base64Frame}`,
                  },
                },
              ],
            },
          ],
          response_format: { type: "json_object" },
          max_tokens: 500,
        });

        frameAnalyses.push(JSON.parse(response.choices[0].message.content!));
      }

      // Clean up frame
      await fs.unlink(framePath);
    }

    // Aggregate frame analyses
    content.analysis = this.aggregateFrameAnalyses(frameAnalyses);

    // Clean up temp directory
    await fs.rmdir(framesDir);
  }

  private async analyzeAudio(content: ContentItem) {
    if (isDevMode) {
      console.log("ðŸ”§ Development mode: Using mock audio analysis");
      const mockText = "This is a sample transcription for development testing purposes.";
      content.analysis.text = mockText;
      content.analysis.adult = { score: Math.random() * 10, category: "safe" };
      content.analysis.violence = { score: Math.random() * 8, category: "none" };
      content.analysis.aiScore = Math.random() * 20;
      return;
    }

    // Transcribe audio using Whisper
    const audioBuffer = await fs.readFile(content.originalPath);

    const transcription = await openai!.audio.transcriptions.create({
      file: new File([audioBuffer], content.metadata.filename),
      model: "whisper-1",
      response_format: "json",
    });

    content.analysis.text = transcription.text;

    // Analyze transcribed text for content
    if (transcription.text) {
      const textAnalysis = await openai!.chat.completions.create({
        model: "gpt-5", // the newest OpenAI model is "gpt-5" which was released August 7, 2025. do not change this unless explicitly requested by the user
        messages: [
          {
            role: "system",
            content:
              "Analyze this transcribed audio text for adult content, hate speech, violence, and other moderation concerns. Return JSON with scores 0-100.",
          },
          {
            role: "user",
            content: transcription.text,
          },
        ],
        response_format: { type: "json_object" },
      });

      const analysis = JSON.parse(textAnalysis.choices[0].message.content!);
      content.analysis.adult = analysis.adult || { score: 0, category: "safe" };
      content.analysis.violence = analysis.violence || {
        score: 0,
        category: "none",
      };
      content.analysis.aiScore = analysis.overall_score || 0;
    }
  }

  private async analyzeText(content: ContentItem) {
    const textContent = await fs.readFile(content.originalPath, "utf-8");

    if (isDevMode) {
      console.log("ðŸ”§ Development mode: Using mock text analysis");
      content.analysis.text = textContent;
      content.analysis.language = "en";
      content.analysis.sentiment = { score: 0.2, magnitude: 0.3 };
      content.analysis.categories = [{ name: "text", confidence: 0.95 }];
      content.analysis.adult = { score: Math.random() * 15, category: "safe" };
      content.analysis.violence = { score: Math.random() * 12, category: "none" };
      content.analysis.aiScore = Math.random() * 25;
      content.analysis.confidence = 90;
      return;
    }

    const response = await openai!.chat.completions.create({
      model: "gpt-5", // the newest OpenAI model is "gpt-5" which was released August 7, 2025. do not change this unless explicitly requested by the user
      messages: [
        {
          role: "system",
          content:
            "Analyze this text content for moderation concerns including adult content, hate speech, violence, harassment, and spam. Return JSON with detailed analysis.",
        },
        {
          role: "user",
          content: textContent,
        },
      ],
      response_format: { type: "json_object" },
    });

    const analysis = JSON.parse(response.choices[0].message.content!);

    content.analysis.text = textContent;
    content.analysis.language = analysis.language;
    content.analysis.sentiment = analysis.sentiment;
    content.analysis.categories = analysis.categories || [];
    content.analysis.adult = analysis.adult || { score: 0, category: "safe" };
    content.analysis.violence = analysis.violence || {
      score: 0,
      category: "none",
    };
    content.analysis.aiScore = analysis.overall_score || 0;
    content.analysis.confidence = 90; // GPT-5 confidence
  }

  private aggregateFrameAnalyses(frameAnalyses: any[]): ContentAnalysis {
    const avgScore = (field: string) =>
      frameAnalyses.reduce((sum, analysis) => sum + (analysis[field] || 0), 0) /
      frameAnalyses.length;

    return {
      aiScore: avgScore("overall_score"),
      confidence: 85,
      categories: [],
      objects: [],
      faces: [],
      adult: {
        score: avgScore("adult_score"),
        category: frameAnalyses[0]?.adult_category || "safe",
      },
      violence: {
        score: avgScore("violence_score"),
        category: frameAnalyses[0]?.violence_category || "none",
      },
      medical: {
        score: avgScore("medical_score"),
        category: frameAnalyses[0]?.medical_category || "none",
      },
      racy: {
        score: avgScore("racy_score"),
        category: frameAnalyses[0]?.racy_category || "none",
      },
      technical: {
        sharpness: avgScore("sharpness"),
        brightness: avgScore("brightness"),
        contrast: avgScore("contrast"),
        noise: avgScore("noise"),
      },
    };
  }

  private applyModerationRules(content: ContentItem) {
    const flags: string[] = [];

    // Adult content thresholds
    if (content.analysis.adult.score > 80) {
      flags.push("explicit_adult");
      content.nsfw = true;
    } else if (content.analysis.adult.score > 50) {
      flags.push("suggestive_adult");
      content.nsfw = true;
    }

    // Violence thresholds
    if (content.analysis.violence.score > 70) {
      flags.push("graphic_violence");
    } else if (content.analysis.violence.score > 40) {
      flags.push("mild_violence");
    }

    // Overall moderation score
    if (content.analysis.aiScore > 75) {
      flags.push("high_risk");
      content.approved = false;
    } else if (content.analysis.aiScore > 50) {
      flags.push("moderate_risk");
    }

    content.moderationFlags = flags;
  }

  private async generateThumbnails(content: ContentItem, task: ProcessingTask) {
    const thumbnailDir = join(process.cwd(), "media", "content", "thumbnails");
    const sizes = [
      { name: "small", size: "150x150" },
      { name: "medium", size: "300x300" },
      { name: "large", size: "600x600" },
    ];

    for (const { name, size } of sizes) {
      const outputPath = join(thumbnailDir, `${content.id}_${name}.jpg`);

      let command: string[] = [];

      if (content.type === "image") {
        command = [
          "-i",
          content.originalPath,
          "-vf",
          `scale=${size}:force_original_aspect_ratio=decrease,pad=${size}:(ow-iw)/2:(oh-ih)/2:black`,
          "-y",
          outputPath,
        ];
      } else if (content.type === "video") {
        const duration = content.metadata.duration || 10;
        const seekTime = duration * 0.3; // 30% into video

        command = [
          "-i",
          content.originalPath,
          "-ss",
          seekTime.toString(),
          "-vframes",
          "1",
          "-vf",
          `scale=${size}:force_original_aspect_ratio=decrease,pad=${size}:(ow-iw)/2:(oh-ih)/2:black`,
          "-y",
          outputPath,
        ];
      }

      if (command.length > 0) {
        await new Promise<void>((resolve, reject) => {
          const process = spawn("ffmpeg", command);

          process.on("close", (code) => {
            if (code === 0) {
              content.processedPaths[`thumbnail_${name}`] = outputPath;
              resolve();
            } else {
              reject(new Error(`Thumbnail generation failed for ${name}`));
            }
          });
        });
      }

      task.progress =
        ((sizes.indexOf({ name, size }) + 1) / sizes.length) * 100;
    }
  }

  private async optimizeContent(content: ContentItem, task: ProcessingTask) {
    const optimizedDir = join(process.cwd(), "media", "content", "optimized");
    const outputPath = join(
      optimizedDir,
      `${content.id}_optimized${extname(content.originalPath)}`,
    );

    let command: string[] = [];

    switch (content.type) {
      case "image":
        command = [
          "-i",
          content.originalPath,
          "-vf",
          "scale=1920:1080:force_original_aspect_ratio=decrease",
          "-q:v",
          "85",
          "-y",
          outputPath,
        ];
        break;

      case "video":
        command = [
          "-i",
          content.originalPath,
          "-c:v",
          "libx264",
          "-preset",
          "medium",
          "-crf",
          "23",
          "-vf",
          "scale=1920:1080:force_original_aspect_ratio=decrease",
          "-c:a",
          "aac",
          "-b:a",
          "128k",
          "-movflags",
          "+faststart",
          "-y",
          outputPath,
        ];
        break;

      case "audio":
        command = [
          "-i",
          content.originalPath,
          "-c:a",
          "aac",
          "-b:a",
          "192k",
          "-ar",
          "48000",
          "-y",
          outputPath,
        ];
        break;
    }

    if (command.length > 0) {
      await new Promise<void>((resolve, reject) => {
        const process = spawn("ffmpeg", command);

        process.on("close", (code) => {
          if (code === 0) {
            content.processedPaths.optimized = outputPath;
            task.progress = 100;
            resolve();
          } else {
            reject(new Error("Content optimization failed"));
          }
        });

        // Track progress for video/audio
        if (
          ["video", "audio"].includes(content.type) &&
          content.metadata.duration
        ) {
          let progressData = "";

          process.stderr?.on("data", (data) => {
            progressData += data.toString();

            const timeMatch = progressData.match(
              /time=(\d{2}):(\d{2}):(\d{2}\.\d{2})/,
            );
            if (timeMatch) {
              const [, hours, minutes, seconds] = timeMatch;
              const currentTime =
                parseInt(hours) * 3600 +
                parseInt(minutes) * 60 +
                parseFloat(seconds);
              task.progress = Math.min(
                100,
                Math.round((currentTime / content.metadata.duration!) * 100),
              );
            }
          });
        }
      });
    }
  }

  private async transcodeVideo(content: ContentItem, task: ProcessingTask) {
    if (content.type !== "video") return;

    const transcodedDir = join(process.cwd(), "media", "content", "transcoded");
    const formats = [
      { name: "mp4_h264", ext: "mp4", codec: "libx264", preset: "medium" },
      { name: "webm_vp9", ext: "webm", codec: "libvpx-vp9", preset: "medium" },
      { name: "hls", ext: "m3u8", codec: "libx264", preset: "fast" },
    ];

    for (let i = 0; i < formats.length; i++) {
      const format = formats[i];
      const outputPath = join(
        transcodedDir,
        `${content.id}_${format.name}.${format.ext}`,
      );

      let command = [
        "-i",
        content.originalPath,
        "-c:v",
        format.codec,
        "-preset",
        format.preset,
        "-crf",
        "23",
        "-c:a",
        format.ext === "webm" ? "libopus" : "aac",
        "-b:a",
        "128k",
      ];

      if (format.name === "hls") {
        command.push(
          "-f",
          "hls",
          "-hls_time",
          "6",
          "-hls_list_size",
          "0",
          "-hls_flags",
          "independent_segments",
        );
      }

      command.push("-y", outputPath);

      await new Promise<void>((resolve, reject) => {
        const process = spawn("ffmpeg", command);

        process.on("close", (code) => {
          if (code === 0) {
            content.processedPaths[format.name] = outputPath;
            resolve();
          } else {
            reject(new Error(`Transcoding failed for ${format.name}`));
          }
        });
      });

      task.progress = ((i + 1) / formats.length) * 100;
    }
  }

  private async addWatermark(content: ContentItem, task: ProcessingTask) {
    const watermarkedDir = join(
      process.cwd(),
      "media",
      "content",
      "watermarked",
    );
    const outputPath = join(
      watermarkedDir,
      `${content.id}_watermarked${extname(content.originalPath)}`,
    );

    let command: string[] = [];

    if (content.type === "image") {
      command = [
        "-i",
        content.originalPath,
        "-vf",
        `drawtext=text='Â© Fanzâ„¢ Unlimited Network LLC':fontsize=24:fontcolor=white@0.8:x=w-tw-10:y=h-th-10`,
        "-y",
        outputPath,
      ];
    } else if (content.type === "video") {
      command = [
        "-i",
        content.originalPath,
        "-vf",
        `drawtext=text='Â© Fanzâ„¢ Unlimited Network LLC':fontsize=24:fontcolor=white@0.8:x=w-tw-10:y=h-th-10`,
        "-c:v",
        "libx264",
        "-c:a",
        "copy",
        "-y",
        outputPath,
      ];
    }

    if (command.length > 0) {
      await new Promise<void>((resolve, reject) => {
        const process = spawn("ffmpeg", command);

        process.on("close", (code) => {
          if (code === 0) {
            content.processedPaths.watermarked = outputPath;
            task.progress = 100;
            resolve();
          } else {
            reject(new Error("Watermark application failed"));
          }
        });
      });
    }
  }

  private detectContentType(ext: string): ContentItem["type"] {
    const imageExts = [".jpg", ".jpeg", ".png", ".gif", ".bmp", ".webp"];
    const videoExts = [".mp4", ".avi", ".mov", ".wmv", ".flv", ".webm", ".mkv"];
    const audioExts = [".mp3", ".wav", ".flac", ".aac", ".ogg", ".m4a"];
    const textExts = [".txt", ".md", ".html", ".json", ".xml"];

    if (imageExts.includes(ext)) return "image";
    if (videoExts.includes(ext)) return "video";
    if (audioExts.includes(ext)) return "audio";
    if (textExts.includes(ext)) return "text";
    return "document";
  }

  private getMimeType(ext: string): string {
    const mimeTypes: Record<string, string> = {
      ".jpg": "image/jpeg",
      ".jpeg": "image/jpeg",
      ".png": "image/png",
      ".gif": "image/gif",
      ".webp": "image/webp",
      ".mp4": "video/mp4",
      ".webm": "video/webm",
      ".mov": "video/quicktime",
      ".avi": "video/x-msvideo",
      ".mp3": "audio/mpeg",
      ".wav": "audio/wav",
      ".flac": "audio/flac",
      ".txt": "text/plain",
      ".html": "text/html",
      ".json": "application/json",
    };

    return mimeTypes[ext] || "application/octet-stream";
  }

  private async calculateFileHash(filePath: string): Promise<string> {
    const crypto = require("crypto");
    const fileBuffer = await fs.readFile(filePath);
    return crypto.createHash("sha256").update(fileBuffer).digest("hex");
  }

  getContent(contentId: string): ContentItem | undefined {
    return this.content.get(contentId);
  }

  getAllContent(): ContentItem[] {
    return Array.from(this.content.values());
  }

  getContentByUser(userId: string): ContentItem[] {
    return Array.from(this.content.values()).filter(
      (item) => item.userId === userId,
    );
  }

  getPendingModeration(): ContentItem[] {
    return Array.from(this.content.values()).filter(
      (item) => !item.approved && item.status === "completed",
    );
  }

  approveContent(contentId: string): boolean {
    const content = this.content.get(contentId);
    if (content) {
      content.approved = true;
      content.moderationFlags = content.moderationFlags.filter(
        (flag) => !flag.includes("risk"),
      );
      this.emit("contentApproved", content);
      return true;
    }
    return false;
  }

  rejectContent(contentId: string, reason: string): boolean {
    const content = this.content.get(contentId);
    if (content) {
      content.approved = false;
      content.moderationFlags.push(`rejected:${reason}`);
      this.emit("contentRejected", content, reason);
      return true;
    }
    return false;
  }

  getTask(taskId: string): ProcessingTask | undefined {
    return this.tasks.get(taskId);
  }

  getAllTasks(): ProcessingTask[] {
    return Array.from(this.tasks.values());
  }

  getStats() {
    const content = Array.from(this.content.values());
    const tasks = Array.from(this.tasks.values());

    return {
      content: {
        total: content.length,
        pending: content.filter((c) => c.status === "pending").length,
        processing: content.filter((c) => c.status === "processing").length,
        completed: content.filter((c) => c.status === "completed").length,
        failed: content.filter((c) => c.status === "failed").length,
        approved: content.filter((c) => c.approved).length,
        nsfw: content.filter((c) => c.nsfw).length,
      },
      tasks: {
        total: tasks.length,
        pending: tasks.filter((t) => t.status === "pending").length,
        processing: tasks.filter((t) => t.status === "processing").length,
        completed: tasks.filter((t) => t.status === "completed").length,
        failed: tasks.filter((t) => t.status === "failed").length,
      },
      processing: {
        activeProcesses: this.activeProcesses,
        maxConcurrentProcesses: this.maxConcurrentProcesses,
        queueLength: this.processingQueue.length,
      },
    };
  }

  setMaxConcurrentProcesses(count: number) {
    this.maxConcurrentProcesses = Math.max(1, count);
  }
}

// Singleton instance
export const contentProcessor = new ContentProcessor();
